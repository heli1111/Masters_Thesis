{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17ughMu7uCIuMm26YZzU76zeqR-8PxVWw",
      "authorship_tag": "ABX9TyOg0AQuDLyoZwUh88LHu6hr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hepuliu/Masters_Thesis/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Master Thesis Simulation - CNN Model\n",
        "\n",
        "*Flood Prevention with Machine Learining - Hepu Liu*\n",
        "\n",
        "---\n",
        "\n",
        "**This Notebook is Dedicated to the CNN Model Simulations**"
      ],
      "metadata": {
        "id": "SK9SqJkgYflY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overall Project Simulation Steps\n",
        "1. Process discharge data from Waldangelbach Station\n",
        "\n",
        "2. Process precipitation data from Baiertal  Station\n",
        "\n",
        "3. Build Prediction Models\n",
        "\n",
        "4. Evaluation of NSE\n",
        "\n",
        "### Variable Naming Conventions\n",
        "\n",
        "- Weather Stations Naming: ('p' for precipitation, 'd' for discharge, 'a' for different stations, 'r' for result)\n",
        "\n",
        "  - da: Waldangelbach Station\n",
        "  - pa: Baiertal Station\n",
        "  - pr: combined/resulting precipitation\n",
        "  - dr: predicted/resulting discharge\n",
        "\n",
        "- Variable Naming Coventions: \n",
        "  - df: data frame\n",
        "  - trs: training set\n",
        "  - tes: testing set\n",
        "  - lstm: LSTM\n",
        "  - cnn: CNN\n",
        "  - lstmss: LSTM-seq2sqe\n"
      ],
      "metadata": {
        "id": "qglbOjh3bvqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "KIiBvKSSYZGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from fbprophet import Prophet\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from math import sqrt\n",
        "from numpy import concatenate\n",
        "from numpy import loadtxt\n",
        "from numpy import array\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZOjIExEcfol",
        "outputId": "accc84da-e87e-4545-997d-896a10367ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function google.colab.drive.mount>"
            ]
          },
          "metadata": {},
          "execution_count": 439
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Datasets"
      ],
      "metadata": {
        "id": "aaJEQP7LYbTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import datafram for CNN\n",
        "df_cnn = pd.read_csv('/content/drive/MyDrive/thesis/dataset/cleaned_df/df_cnn.csv')\n",
        "df_cnn.head()"
      ],
      "metadata": {
        "id": "YKCS3Ce1epsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "1fFHbl2kREy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Processing for Multivariable CNN - Small Sample Size for Testing\n",
        "df_cnn = df_cnn.iloc[:2500, :]\n",
        "df_cnn = df_cnn.set_index('ds')\n",
        "df_cnn = df_cnn[['temp', 'rad', 'preci', 'y']]\n",
        "df_cnn = df_cnn.to_numpy()"
      ],
      "metadata": {
        "id": "B-4_FQyuf73l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN - split into train and test sets\n",
        "trs_cnn = df_cnn[:2000, :]\n",
        "tes_cnn = df_cnn[2000:, :]"
      ],
      "metadata": {
        "id": "lLdcWHtbCEMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Data Processing - split multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# convert training set into input/output\n",
        "trs_cnn_X, trs_cnn_y = split_sequences(trs_cnn, n_steps)\n",
        "print(trs_cnn_X.shape, trs_cnn_y.shape)\n",
        "# convert testing set into input/output\n",
        "tes_cnn_X, tes_cnn_y = split_sequences(tes_cnn, n_steps)\n",
        "print(tes_cnn_X.shape, tes_cnn_y.shape)\n",
        "\n",
        "# define number of feature variables\n",
        "n_features = trs_cnn_X.shape[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LPtcEbrjkJH",
        "outputId": "0274f0f6-fb51-4205-d289-39b5a8eb0338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1998, 3, 3) (1998,)\n",
            "(498, 3, 3) (498,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "SerPe_Z59GSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model Definition\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(50, activation='relu'))\n",
        "model_cnn.add(Dense(1))\n",
        "model_cnn.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "RkITF_J59QUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "wlmgXfFtD08B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Fit Model\n",
        "cnn_history = model_cnn.fit(trs_cnn_X, trs_cnn_y, validation_data=(tes_cnn_X, tes_cnn_y), epochs=2000, verbose=0)\n"
      ],
      "metadata": {
        "id": "Z-bYmQN39Ran"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Prediction\n",
        "trs_cnn_pred = model_cnn.predict(trs_cnn_X)\n",
        "tes_cnn_pred = model_cnn.predict(tes_cnn_X)\n",
        "# print('Train rmse:', np.sqrt(mean_squared_error(trs_cnn_y, trs_cnn_pred)))\n",
        "# print('Validation rmse:', np.sqrt(mean_squared_error(tes_cnn_y, tes_cnn_pred)))\n"
      ],
      "metadata": {
        "id": "q-IX_jExZUYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trs_cnn_pred = trs_cnn_pred.reshape(-1,1)\n",
        "trs_cnn_y = trs_cnn_y.reshape(-1,1)\n",
        "tes_cnn_pred = tes_cnn_pred.reshape(-1,1)\n",
        "tes_cnn_y = tes_cnn_y.reshape(-1,1)"
      ],
      "metadata": {
        "id": "ABA8NEG9h3of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate NSE\n",
        "nse_trs_cnn = 1-(np.sum((trs_cnn_pred-trs_cnn_y)**2)/np.sum((trs_cnn_y-np.mean(trs_cnn_y))**2))\n",
        "nse_tes_cnn = 1-(np.sum((tes_cnn_pred-tes_cnn_y)**2)/np.sum((tes_cnn_y-np.mean(tes_cnn_y))**2))\n",
        "\n",
        "print('Train NSE: %.3f' % nse_trs_cnn)\n",
        "print('Test NSE: %.3f' % nse_tes_cnn)\n",
        "\n",
        "# # calculate RMSE\n",
        "# rmse_trs_cnn = np.sqrt(mean_squared_error(trs_cnn_y, trs_cnn_pred))\n",
        "# rmse_tes_cnn = np.sqrt(mean_squared_error(tes_cnn_y, tes_cnn_pred))\n",
        "# print('Train RMSE: %.3f', % rmse_trs_cnn)\n",
        "# print('Test RMSE: %.3f', % rmse_tes_cnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3G4rEjBbpTk",
        "outputId": "fc890332-07d5-4247-a0dc-3faccd5cce1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train NSE: 0.537\n",
            "Test NSE: 0.537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Archive"
      ],
      "metadata": {
        "id": "6w2EwQydjZZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # NSE Calculation and Plot\n",
        "\n",
        "# o = np.array([1,2,3,4,5,6,7,8,9,10,2,3,4,5,6,7])\n",
        "# m = np.array([1.1,2.2,3.2,4,5,6.1,7.2,8.5,8,10.5,1,2,4,5,6,7])\n",
        "# # nse = 1-(np.sum((p-t)**2)/np.sum((t-np.mean(t))**2))\n",
        "# # print('Test NSE: %.3f' % nse)\n",
        "# # plot\n",
        "\n",
        "\n",
        "# fig= plt.figure(figsize=(14, 4))\n",
        "# plt.title('Insert Title')\n",
        "# plt.plot(o, label='observed', color='#00688b', linewidth=0.5)\n",
        "# plt.plot(m, label='model', color='#ee7600', linewidth=0.5)\n",
        "# plt.plot([], [], ' ', label='NSE = %.3f' % nse)\n",
        "# plt.ylabel('y label')\n",
        "# plt.ylabel('x label')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "5HHU6Evxk47G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}