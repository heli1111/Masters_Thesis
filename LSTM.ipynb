{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bW3k4dwg1hAgBd_JoSOGaj82uS6v2lD5",
      "authorship_tag": "ABX9TyPyxLyGzAnvzBP1PhDXEUpW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hepuliu/Masters_Thesis/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Master Thesis Simulation - LSTM Model\n",
        "\n",
        "*Flood Prevention with Machine Learining - Hepu Liu*\n",
        "\n",
        "---\n",
        "\n",
        "**This Notebook is Dedicated to the LSTM Model Simulations**"
      ],
      "metadata": {
        "id": "stxpzyENrS9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overall Project Simulation Steps\n",
        "1. Process discharge data from Waldangelbach Station\n",
        "\n",
        "2. Process precipitation data from Baiertal  Station\n",
        "\n",
        "3. Build Prediction Models\n",
        "\n",
        "4. Evaluation of NSE\n",
        "\n",
        "### Variable Naming Conventions\n",
        "\n",
        "- Weather Stations Naming: ('p' for precipitation, 'd' for discharge, 'a' for different stations, 'r' for result)\n",
        "\n",
        "  - da: Waldangelbach Station\n",
        "  - pa: Baiertal Station\n",
        "  - pr: combined/resulting precipitation\n",
        "  - dr: predicted/resulting discharge\n",
        "\n",
        "- Variable Naming Coventions: \n",
        "  - df: data frame\n",
        "  - trs: training set\n",
        "  - tes: testing set\n",
        "  - lstm: LSTM\n",
        "  - cnn: CNN\n",
        "  - lstmss: LSTM-seq2sqe\n"
      ],
      "metadata": {
        "id": "vTni1B9BrUaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "QKzUy-aprWdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from fbprophet import Prophet\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from math import sqrt\n",
        "from numpy import concatenate\n",
        "from numpy import loadtxt\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount"
      ],
      "metadata": {
        "id": "i3obmBLsrgIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ed0d3e-81d4-43a1-fd7b-0503f05c14f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function google.colab.drive.mount>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Datasets"
      ],
      "metadata": {
        "id": "OjEf5D5krZJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # import datafram for LSTM\n",
        "# df_lstm = pd.read_csv('/content/drive/MyDrive/thesis/dataset/cleaned_df/df_lstm.csv')\n",
        "# df_lstm.head()"
      ],
      "metadata": {
        "id": "9jEiB2uNbpCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "QW4JNsmrrlZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # LSTM\n",
        "# # convert series to supervised learning\n",
        "# def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "#   n_vars = 1 if type(data) is list else data.shape[1]\n",
        "#   df = DataFrame(data)\n",
        "#   cols, names = list(), list()\n",
        "# \t# input sequence (t-n, ... t-1)\n",
        "#   for i in range(n_in, 0, -1):\n",
        "#     cols.append(df.shift(i))\n",
        "#     names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "# \t# forecast sequence (t, t+1, ... t+n)\n",
        "#   for i in range(0, n_out):\n",
        "#     cols.append(df.shift(-i))\n",
        "#     if i == 0:\n",
        "#       names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "#     else:\n",
        "#       names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "# \t# put it all together\n",
        "#   agg = concat(cols, axis=1)\n",
        "#   agg.columns = names\n",
        "#   # drop rows with NaN values\n",
        "#   if dropnan:\n",
        "#     agg.dropna(inplace=True)\n",
        "#   return agg\n",
        "\n",
        "# # assigne df values\n",
        "# values = df_lstm.values\n",
        "# # ensure all data is float\n",
        "# values = values.astype('float32')\n",
        "# # normalize features\n",
        "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# scaled = scaler.fit_transform(values)\n",
        "# # frame as supervised learning\n",
        "# df_lstm_reframed = series_to_supervised(scaled, 1, 1)\n",
        "# # drop columns not to be predicted\n",
        "# df_lstm_reframed.drop(df_lstm_reframed.columns[[5,6,7]], axis=1, inplace=True)\n",
        "# df_lstm_reframed"
      ],
      "metadata": {
        "id": "ieKBGM_wfdoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # LSTM\n",
        "# # split into train and test sets\n",
        "# values = df_lstm_reframed.values\n",
        "# n = 9*365*24\n",
        "# # n = 1000\n",
        "# train = values[:n, :]\n",
        "# test = values[n:, :]\n",
        "# # split into input and outputs\n",
        "# train_X, train_y = train[:, :-1], train[:, -1]\n",
        "# test_X, test_y = test[:, :-1], test[:, -1]\n",
        "# # reshape input to be 3D [samples, timesteps, features]\n",
        "# train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "# test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "# print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ],
      "metadata": {
        "id": "zoYG86ND3A_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Model Prediction\n"
      ],
      "metadata": {
        "id": "Uor3rlPR1rpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # LSTM\n",
        "# # design network\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "# model.add(Dense(1))\n",
        "# model.compile(loss='mae', optimizer='adam')\n",
        "\n",
        "# # fit network\n",
        "# history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
        "\n",
        "# # plot history\n",
        "# plt.plot(history.history['loss'], label='train')\n",
        "# plt.plot(history.history['val_loss'], label='test')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# fig= plt.figure(figsize=(14, 4))\n",
        "# plt.title('Insert Title')\n",
        "# plt.plot(o, label='observed', color='#00688b', linewidth=0.5)\n",
        "# plt.plot(m, label='model', color='#ee7600', linewidth=0.5)\n",
        "# plt.plot([], [], ' ', label='NSE = %.3f' % nse)\n",
        "# plt.ylabel('y label')\n",
        "# plt.ylabel('x label')\n",
        "# plt.legend()\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "k1k-Fwof3U1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "U-GN4TBS16oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # LSTM\n",
        "# # Training Accuracy Evaluations\n",
        "# # make a prediction\n",
        "# yhat = model.predict(train_X)\n",
        "# train_X = train_X.reshape((train_X.shape[0], train_X.shape[2]))\n",
        "# # invert scaling for forecast\n",
        "# inv_yhat = concatenate((yhat, train_X[:, 1:]), axis=1)\n",
        "# inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "# inv_yhat = inv_yhat[:,0]\n",
        "# # invert scaling for actual\n",
        "# train_y = train_y.reshape((len(train_y), 1))\n",
        "# inv_y = concatenate((train_y, train_X[:, 1:]), axis=1)\n",
        "# inv_y = scaler.inverse_transform(inv_y)\n",
        "# inv_y = inv_y[:,0]\n",
        "\n",
        "# # calculate RMSE\n",
        "# rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "# print('Test RMSE: %.3f' % rmse)\n",
        "\n",
        "# # calculate NSE\n",
        "# nse = 1-(np.sum((inv_yhat-inv_y)**2)/np.sum((inv_y-np.mean(inv_y))**2))\n",
        "# print('Test NSE: %.3f' % nse)\n",
        "\n",
        "# # plot history\n",
        "# plt.plot(inv_y, label='train')\n",
        "# plt.plot(inv_yhat, label='predict')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "aSg71hIM4Voy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # LSTM\n",
        "# # Testing Accuracy Evaluations\n",
        "# # make a prediction\n",
        "# yhat = model.predict(test_X)\n",
        "# test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
        "# # invert scaling for forecast\n",
        "# inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
        "# inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "# inv_yhat = inv_yhat[:,0]\n",
        "# # invert scaling for actual\n",
        "# test_y = test_y.reshape((len(test_y), 1))\n",
        "# inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
        "# inv_y = scaler.inverse_transform(inv_y)\n",
        "# inv_y = inv_y[:,0]\n",
        "\n",
        "# # calculate RMSE\n",
        "# rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "# print('Test RMSE: %.3f' % rmse)\n",
        "\n",
        "# # calculate NSE\n",
        "# nse = 1-(np.sum((inv_yhat-inv_y)**2)/np.sum((inv_y-np.mean(inv_y))**2))\n",
        "# print('Test NSE: %.3f' % nse)\n",
        "\n",
        "# # plot history\n",
        "# plt.plot(inv_y, label='train')\n",
        "# plt.plot(inv_yhat, label='predict')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "8iZcIzl_UD7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Archive"
      ],
      "metadata": {
        "id": "uupgN12or3e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # NSE Calculation and Plot\n",
        "\n",
        "# o = np.array([1,2,3,4,5,6,7,8,9,10,2,3,4,5,6,7])\n",
        "# m = np.array([1.1,2.2,3.2,4,5,6.1,7.2,8.5,8,10.5,1,2,4,5,6,7])\n",
        "# # nse = 1-(np.sum((p-t)**2)/np.sum((t-np.mean(t))**2))\n",
        "# # print('Test NSE: %.3f' % nse)\n",
        "# # plot\n",
        "\n",
        "\n",
        "# fig= plt.figure(figsize=(14, 4))\n",
        "# plt.title('Insert Title')\n",
        "# plt.plot(o, label='observed', color='#00688b', linewidth=0.5)\n",
        "# plt.plot(m, label='model', color='#ee7600', linewidth=0.5)\n",
        "# plt.plot([], [], ' ', label='NSE = %.3f' % nse)\n",
        "# plt.ylabel('y label')\n",
        "# plt.ylabel('x label')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "iSt9vQHm2bNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Data Processing for Multivariable LSTM - Small Testing Sample Set\n",
        "# # df_lstm = df_lstm.iloc[:1500, :]\n",
        "# df_lstm = df_lstm.set_index('ds')\n",
        "# df_lstm"
      ],
      "metadata": {
        "id": "Y5nMHum5aNrw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}